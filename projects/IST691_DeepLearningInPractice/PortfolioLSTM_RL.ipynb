{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 384
    },
    "id": "OPszxZmBaZDA",
    "outputId": "5717df71-b7a1-47bd-8d68-415e1db5b321"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gym'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgym\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgym\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m spaces\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01myfinance\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01myf\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'gym'"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "from gym import spaces\n",
    "import yfinance as yf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "\n",
    "# Define the Gym Environment\n",
    "class StockTradingEnv(gym.Env):\n",
    "    metadata = {'render.modes': ['human']}\n",
    "\n",
    "    def __init__(self, data, lstm_models, scalers):\n",
    "        super(StockTradingEnv, self).__init__()\n",
    "\n",
    "        # Data is now a dictionary mapping tickers to their DataFrame\n",
    "        self.data = data\n",
    "        # LSTM models and scalers for each of the top stocks\n",
    "        self.lstm_models = lstm_models\n",
    "        self.scalers = scalers\n",
    "\n",
    "        # Define the action space as a vector where each element corresponds to an action for a stock\n",
    "        # For simplicity, let's define each action as the amount of money to invest in each stock\n",
    "        self.action_space = spaces.Box(low=0, high=1, shape=(len(lstm_models),), dtype=np.float32)\n",
    "\n",
    "        # Observation space will be a concatenation of all stock states and their predictions\n",
    "        obs_dim = sum(len(df.columns) + 1 for df in data.values())  # +1 for each prediction\n",
    "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(obs_dim,), dtype=np.float32)\n",
    "\n",
    "        self.initial_balance = 10000\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.balance = self.initial_balance\n",
    "        self.index = {ticker: 0 for ticker in self.data}  # Track index for each stock\n",
    "        self.done = False\n",
    "        self.total_reward = 0\n",
    "        return self._next_observation()\n",
    "\n",
    "\n",
    "    def set_new_models_scalers(self, new_lstm_models, new_scalers, top_tickers):\n",
    "        self.lstm_models = new_lstm_models\n",
    "        self.scalers = new_scalers\n",
    "        self.top_tickers = top_tickers\n",
    "        print(\"Environment updated with new top stocks:\", top_tickers)\n",
    "        self.reset()\n",
    "\n",
    "\n",
    "    def _next_observation(self):\n",
    "        # Concatenate states and predictions for all stocks\n",
    "        obs = np.concatenate([\n",
    "            np.append(self.data[ticker].iloc[index].values, self._predict_next_close(ticker, index))\n",
    "            for ticker, index in self.index.items()\n",
    "        ])\n",
    "        return obs\n",
    "\n",
    "    def _predict_next_close(self, ticker, index):\n",
    "        if index < 5:\n",
    "            return 0  # Not enough data to predict\n",
    "\n",
    "        df = self.data[ticker]\n",
    "        last_sequence = df['Close'].iloc[index-5:index].values.reshape(-1, 1)\n",
    "        last_sequence_scaled = self.scalers[ticker].transform(last_sequence)\n",
    "        last_sequence_reshaped = np.reshape(last_sequence_scaled, (1, 5, 1))\n",
    "\n",
    "        predicted_scaled = self.lstm_models[ticker].predict(last_sequence_reshaped)\n",
    "        predicted = self.scalers[ticker].inverse_transform(predicted_scaled)[0, 0]\n",
    "        return predicted\n",
    "\n",
    "    # ... class definition ...\n",
    "\n",
    "    def step(self, action):\n",
    "        reward = 0\n",
    "        done = False\n",
    "\n",
    "        # Update balance and reward for each stock based on the action taken\n",
    "        for ticker, investment_ratio in zip(self.lstm_models.keys(), action):\n",
    "            current_index = self.index[ticker]\n",
    "            current_row = self.data[ticker].iloc[current_index]\n",
    "            next_index = min(current_index + 1, len(self.data[ticker]) - 1)\n",
    "            next_row = self.data[ticker].iloc[next_index]\n",
    "\n",
    "            # Calculate investment and return for this stock\n",
    "            investment = self.balance * investment_ratio\n",
    "            stock_return = (next_row['Close'] - current_row['Open']) / current_row['Open'] * investment\n",
    "            reward += stock_return\n",
    "\n",
    "            self.index[ticker] = next_index\n",
    "            if next_index >= len(self.data[ticker]) - 1:\n",
    "                done = True  # End the episode if we run out of data for any stock\n",
    "\n",
    "        self.balance += reward  # Update balance with the combined reward from all actions\n",
    "        self.total_reward += reward\n",
    "\n",
    "        # If the episode is done and we haven't made any money, penalize the agent\n",
    "        if done and self.total_reward <= 0:\n",
    "            reward -= 1\n",
    "\n",
    "        next_state = self._next_observation()\n",
    "\n",
    "        return next_state, reward, done, {}\n",
    "\n",
    "# Function to fetch data from Yahoo Finance\n",
    "def fetch_data(tickers, start_date, end_date):\n",
    "    data = {}\n",
    "    for ticker in tickers:\n",
    "        stock_data = yf.download(ticker, start=start_date, end=end_date, progress=False)\n",
    "        stock_data['Return'] = stock_data['Close'].pct_change()\n",
    "        data[ticker] = stock_data.dropna()\n",
    "    return data\n",
    "\n",
    "# Function to train LSTM models\n",
    "def train_lstm_models(data):\n",
    "    lstm_models = {}\n",
    "    scalers = {}\n",
    "\n",
    "    for ticker, df in data.items():\n",
    "        df = df.dropna()  # Ensure there are no NaN values in the data\n",
    "\n",
    "        # Scale the 'Close' column\n",
    "        scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        scaled_close = scaler.fit_transform(df[['Close']])\n",
    "\n",
    "        # Create sequences for LSTM training\n",
    "        sequence_length = 5\n",
    "        X, y = [], []\n",
    "        for i in range(sequence_length, len(df)):\n",
    "            X.append(scaled_close[i - sequence_length:i, 0])\n",
    "            y.append(scaled_close[i, 0])\n",
    "\n",
    "        # Convert to numpy arrays and reshape for LSTM\n",
    "        X, y = np.array(X), np.array(y)\n",
    "        X = X.reshape((X.shape[0], X.shape[1], 1))\n",
    "\n",
    "        # Build the LSTM model\n",
    "        model = Sequential([\n",
    "            LSTM(units=50, return_sequences=True, input_shape=(X.shape[1], 1)),\n",
    "            LSTM(units=50),\n",
    "            Dense(units=1)\n",
    "        ])\n",
    "        model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "        # Train the model\n",
    "        model.fit(X, y, epochs=20, batch_size=32, verbose=0)\n",
    "\n",
    "        lstm_models[ticker] = model\n",
    "        scalers[ticker] = scaler\n",
    "\n",
    "    return lstm_models, scalers\n",
    "\n",
    "# Sort the tickers by performance and pick the top 5\n",
    "def sort_stocks_by_performance(data):\n",
    "    performance = {ticker: df['Return'].sum() for ticker, df in data.items()}\n",
    "    sorted_tickers = sorted(performance, key=performance.get, reverse=True)\n",
    "    top_tickers = sorted_tickers[:5]\n",
    "    print(\"Top 5 performing stocks:\", top_tickers)\n",
    "    return top_tickers\n",
    "\n",
    "\n",
    "# Main code to create the environment and train models\n",
    "tickers = [\n",
    "    'AAPL', 'MSFT', 'GOOG', 'AMZN','TSLA', 'BRK-B', 'JNJ', 'JPM', 'V', 'PG', 'UNH', 'DIS', 'NVDA', 'HD',\n",
    "    'PYPL', 'BAC', 'VZ', 'ADBE', 'CMCSA', 'NFLX', 'KO', 'PFE', 'NKE', 'T', 'ABT', 'PEP', 'CVX', 'ORCL', 'CSCO',\n",
    "    'XOM', 'ACN', 'TMO', 'AVGO', 'QCOM', 'COST', 'C', 'LLY', 'WFC', 'DHR', 'MCD', 'MDT', 'INTC', 'TXN', 'HON',\n",
    "    'UNP', 'BMY', 'LIN', 'BA', 'AMGN', 'IBM', 'GE', 'MMM', 'SBUX', 'RTX', 'CAT', 'DE', 'GS', 'MS', 'CVS', 'MMM'\n",
    "]\n",
    "\n",
    "start_date = \"2021-01-01\"\n",
    "end_date = \"2023-01-01\"\n",
    "\n",
    "data = fetch_data(tickers, start_date, end_date)\n",
    "top_tickers = sort_stocks_by_performance(data)\n",
    "top_data = {ticker: data[ticker] for ticker in top_tickers}\n",
    "lstm_models, scalers = train_lstm_models(top_data)\n",
    "\n",
    "# Create a single environment that manages a portfolio of the top stocks\n",
    "env = StockTradingEnv(top_data, lstm_models, scalers)\n",
    "\n",
    "from stable_baselines3 import A2C\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "\n",
    "# Check if the environment follows Gym API\n",
    "#env = StockTradingEnv(top_data, lstm_models, scalers)\n",
    "check_env(env)\n",
    "\n",
    "# ... previous code ...\n",
    "\n",
    "# Initialize the A2C agent from Stable Baselines3\n",
    "agent = A2C(\"MlpPolicy\", env, verbose=1)\n",
    "\n",
    "# Define update frequency for the training loop to re-evaluate top stocks\n",
    "update_frequency = 10  # For example, update every 10 episodes\n",
    "\n",
    "# Train the agent\n",
    "total_timesteps = 0\n",
    "num_episodes = 20  # Set the number of episodes for training\n",
    "episode_rewards = []  # To store rewards for each episode, for analysis and plotting\n",
    "\n",
    "\n",
    "for episode in range(num_episodes):\n",
    "    state = env.reset()\n",
    "    total_episode_reward = 0\n",
    "    steps = 0\n",
    "\n",
    "    while True:\n",
    "        action, _states = agent.predict(state, deterministic=True)\n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "        agent.rollout_buffer.add(state, action, reward, _states, done, next_state)  # Add to buffer\n",
    "        state = next_state\n",
    "        total_episode_reward += reward\n",
    "        steps += 1\n",
    "\n",
    "        if done:\n",
    "              episode_rewards.append(total_episode_reward)\n",
    "              print(f\"Episode: {episode + 1}, Total Reward: {total_episode_reward}, Steps: {steps}\")\n",
    "              break\n",
    "\n",
    "        total_timesteps += steps\n",
    "\n",
    "  # The learning process for A2C in Stable Baselines3 is integrated into the predict method.\n",
    "  # After the episodes are done, you typically call the learn method like this:\n",
    "agent.learn(total_timesteps=total_timesteps)\n",
    "\n",
    " # Update top stocks and retrain LSTM models periodically\n",
    "\n",
    "if episode % update_frequency == 0 and episode > 0:\n",
    "            print(\"Updating top stocks and retraining models...\")\n",
    "            data = fetch_data(tickers, start_date, end_date)\n",
    "            top_tickers = sort_stocks_by_performance(data)\n",
    "            top_data = {ticker: data[ticker] for ticker in top_tickers}\n",
    "            lstm_models, scalers = train_lstm_models(top_data)\n",
    "            env.set_new_models_scalers(lstm_models, scalers, top_tickers)\n",
    "\n",
    "\n",
    "# Learn outside the loop for the specified total timesteps\n",
    "agent.learn(total_timesteps=total_timesteps)\n",
    "\n",
    "# After training, you can analyze the performance of the agent\n",
    "# For example, you could plot the episode_rewards list to see the learning curve\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "opNjH5rcuQ5L",
    "outputId": "4a60f373-df80-4655-a290-d90bef23a1c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gym in /usr/local/lib/python3.10/dist-packages (0.26.2)\n",
      "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from gym) (1.23.5)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym) (2.2.1)\n",
      "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym) (0.0.8)\n"
     ]
    }
   ],
   "source": [
    "!pip install gym --upgrade\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a6QqouKajzdr"
   },
   "outputs": [],
   "source": [
    "!pip install stable-baselines3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NPc9M1OsbZfp"
   },
   "source": [
    "In this code, the environment now manages a portfolio of stocks instead of just one. The action_space is redefined to allocate a fraction of the balance to each stock, and the observation_space includes information from all top stocks. The step function updates the balance based on the investment action taken for each stock.\n",
    "\n",
    "The reward is calculated as the sum of returns from all stocks in the portfolio. If any stock runs out of data (i.e., reaches the end of the DataFrame), the episode ends (done is set to True).\n",
    "\n",
    "To use this environment, create an instance by passing the data, models, and scalers for the top stocks, and then integrate it with your RL agent's training loop. The RL agent will need to be capable of handling the multi-dimensional action space where each dimension corresponds to a stock in the portfolio.\n",
    "\n",
    "Please make sure that the LSTM models are properly trained and the scalers are fit to the data before you create the environment instance. The training loop will need to be adjusted to handle the new action space's structure and the multi-stock portfolio's state representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T9gMW8IMbaGW",
    "outputId": "758c4bab-2c50-45a6-ca4f-b325190ed2c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gymnasium in /usr/local/lib/python3.10/dist-packages (0.29.1)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (1.23.5)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (2.2.1)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (4.5.0)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (0.0.4)\n"
     ]
    }
   ],
   "source": [
    "pip install gymnasium\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "VSv_P-TAr9mW"
   },
   "outputs": [],
   "source": [
    "\n",
    "import gymnasium as gym\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "osc7g46FsKAp",
    "outputId": "5a8a9292-dd57-4b17-e7bb-d7e3f3495b8d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: stable-baselines3[extra] in /usr/local/lib/python3.10/dist-packages (2.1.0)\n",
      "Requirement already satisfied: gymnasium<0.30,>=0.28.1 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (0.29.1)\n",
      "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (1.23.5)\n",
      "Requirement already satisfied: torch>=1.13 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (2.1.0+cu118)\n",
      "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (2.2.1)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (1.5.3)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (3.7.1)\n",
      "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (4.8.0.76)\n",
      "Requirement already satisfied: pygame in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (2.5.2)\n",
      "Requirement already satisfied: tensorboard>=2.9.1 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (2.14.1)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (5.9.5)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (4.66.1)\n",
      "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (13.6.0)\n",
      "Collecting shimmy[atari]~=1.1.0 (from stable-baselines3[extra])\n",
      "  Downloading Shimmy-1.1.0-py3-none-any.whl (37 kB)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (9.4.0)\n",
      "Collecting autorom[accept-rom-license]~=0.6.1 (from stable-baselines3[extra])\n",
      "  Downloading AutoROM-0.6.1-py3-none-any.whl (9.4 kB)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from autorom[accept-rom-license]~=0.6.1->stable-baselines3[extra]) (8.1.7)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from autorom[accept-rom-license]~=0.6.1->stable-baselines3[extra]) (2.31.0)\n",
      "Collecting AutoROM.accept-rom-license (from autorom[accept-rom-license]~=0.6.1->stable-baselines3[extra])\n",
      "  Downloading AutoROM.accept-rom-license-0.6.1.tar.gz (434 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m434.7/434.7 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium<0.30,>=0.28.1->stable-baselines3[extra]) (4.5.0)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium<0.30,>=0.28.1->stable-baselines3[extra]) (0.0.4)\n",
      "Collecting ale-py~=0.8.1 (from shimmy[atari]~=1.1.0->stable-baselines3[extra])\n",
      "  Downloading ale_py-0.8.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m45.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.4.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.59.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (2.17.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.5)\n",
      "Requirement already satisfied: protobuf>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.20.3)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (67.7.2)\n",
      "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.16.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.0.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3[extra]) (3.12.4)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3[extra]) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3[extra]) (3.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3[extra]) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3[extra]) (2023.6.0)\n",
      "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3[extra]) (2.1.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3[extra]) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3[extra]) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3[extra]) (4.43.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3[extra]) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3[extra]) (23.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3[extra]) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3[extra]) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->stable-baselines3[extra]) (2023.3.post1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->stable-baselines3[extra]) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->stable-baselines3[extra]) (2.16.1)\n",
      "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from ale-py~=0.8.1->shimmy[atari]~=1.1.0->stable-baselines3[extra]) (6.1.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard>=2.9.1->stable-baselines3[extra]) (1.3.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->stable-baselines3[extra]) (0.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->autorom[accept-rom-license]~=0.6.1->stable-baselines3[extra]) (3.3.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->autorom[accept-rom-license]~=0.6.1->stable-baselines3[extra]) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->autorom[accept-rom-license]~=0.6.1->stable-baselines3[extra]) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->autorom[accept-rom-license]~=0.6.1->stable-baselines3[extra]) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.9.1->stable-baselines3[extra]) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13->stable-baselines3[extra]) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard>=2.9.1->stable-baselines3[extra]) (3.2.2)\n",
      "Building wheels for collected packages: AutoROM.accept-rom-license\n",
      "  Building wheel for AutoROM.accept-rom-license (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for AutoROM.accept-rom-license: filename=AutoROM.accept_rom_license-0.6.1-py3-none-any.whl size=446660 sha256=d9fe786fa9a8d58ffe798af971c9f76fc057435c3d7d31e94fc919f3c553c846\n",
      "  Stored in directory: /root/.cache/pip/wheels/6b/1b/ef/a43ff1a2f1736d5711faa1ba4c1f61be1131b8899e6a057811\n",
      "Successfully built AutoROM.accept-rom-license\n",
      "Installing collected packages: ale-py, shimmy, AutoROM.accept-rom-license, autorom\n",
      "Successfully installed AutoROM.accept-rom-license-0.6.1 ale-py-0.8.1 autorom-0.6.1 shimmy-1.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install stable-baselines3[extra]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "az1IF56xwB1L"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
